{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small text active learning example\n",
    "\n",
    "taken from https://rubrix.readthedocs.io/en/stable/tutorials/active_learning_with_small_text.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/src/.venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Found cached dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
      "100%|██████████| 2/2 [00:00<00:00, 33.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Configs\n",
    "DATASET = \"bergr7/weakly_supervised_ag_news\"\n",
    "TRANSFORMER_MODEL = \"distilbert-base-uncased\"\n",
    "LABELS = datasets.load_dataset('ag_news')[\"train\"].features[\"label\"].names\n",
    "NUM_SAMPLES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration bergr7--weakly_supervised_ag_news-6f78f309523478bd\n",
      "Found cached dataset csv (/root/.cache/huggingface/datasets/bergr7___csv/bergr7--weakly_supervised_ag_news-6f78f309523478bd/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n",
      "100%|██████████| 3/3 [00:00<00:00, 410.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from app.model.train_model import load_data\n",
    "\n",
    "ag_news_data = load_data(split=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 37340\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 24000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ag_news_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 18.9kB/s]\n",
      "Downloading: 100%|██████████| 483/483 [00:00<00:00, 381kB/s]\n",
      "Downloading: 100%|██████████| 232k/232k [00:00<00:00, 429kB/s]  \n",
      "Downloading: 100%|██████████| 466k/466k [00:00<00:00, 759kB/s]  \n",
      "100%|██████████| 38/38 [00:10<00:00,  3.71ba/s]\n",
      "100%|██████████| 24/24 [00:07<00:00,  3.05ba/s]\n",
      "100%|██████████| 8/8 [00:02<00:00,  3.12ba/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL)\n",
    "\n",
    "# Helper function to tokenize the input text\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Tokenize dataset\n",
    "data_tokenized = ag_news_data.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "# Set convenient output format\n",
    "data_tokenized.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/src/.venv/lib/python3.10/site-packages/small_text/data/datasets.py:29: UserWarning: Passing target_labels=None is discouraged as it can lead to unintended results in combination with indexing and cloning. Moreover, explicit target labels might be required in the next major version.\n",
      "  warnings.warn('Passing target_labels=None is discouraged as it can lead to '\n"
     ]
    }
   ],
   "source": [
    "from small_text.integrations.transformers import TransformersDataset\n",
    "from small_text.base import LABEL_UNLABELED\n",
    "\n",
    "\n",
    "# Create tuples from the tokenized training data\n",
    "data = [\n",
    "    # Need to add an extra dimension to indicate a batch size of 1 -> [None]\n",
    "    (row[\"input_ids\"][None], row[\"attention_mask\"][None], LABEL_UNLABELED)\n",
    "    for row in data_tokenized[\"train\"]\n",
    "]\n",
    "\n",
    "# Create the dataset for small-text\n",
    "dataset = TransformersDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37340"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation dataset\n",
    "data_test = [\n",
    "    (row[\"input_ids\"][None], row[\"attention_mask\"][None], int(row[\"label\"]))\n",
    "    for row in data_tokenized[\"validation\"]\n",
    "]\n",
    "dataset_test = TransformersDataset(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from small_text.integrations.transformers.classifiers.factories import TransformerBasedClassificationFactory\n",
    "from small_text.integrations.transformers import TransformerModelArguments\n",
    "from small_text.query_strategies import LeastConfidence\n",
    "from small_text.active_learner import PoolBasedActiveLearner\n",
    "\n",
    "\n",
    "# Define our classifier\n",
    "clf_factory = TransformerBasedClassificationFactory(\n",
    "    TransformerModelArguments(TRANSFORMER_MODEL),\n",
    "    num_classes=4,\n",
    "    # If you have a cuda device, specify it here.\n",
    "    # Otherwise, just remove the following line.\n",
    "    kwargs={\"device\": \"cuda\"}\n",
    ")\n",
    "\n",
    "# Define our query strategy\n",
    "query_strategy = LeastConfidence()\n",
    "\n",
    "# Use the active learner with a pool containing all unlabeled data\n",
    "active_learner = PoolBasedActiveLearner(clf_factory, query_strategy, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from small_text.initialization import random_initialization\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "# Number of samples in our queried batches\n",
    "NUM_SAMPLES = 5\n",
    "\n",
    "# Randomly draw an initial subset from the data pool\n",
    "initial_indices = random_initialization(dataset, NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30992,  8317, 17797, 23232, 12463])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rubrix as rb\n",
    "import os\n",
    "\n",
    "RUBRIX_URL = os.getenv(\"RUBRIX_API_URL\", \"http://localhost:6900\")\n",
    "\n",
    "rb.init(api_url=RUBRIX_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 records logged to http://rubrix:80/datasets/rubrix/test_with_active_learning_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BulkResponse(dataset='test_with_active_learning_test', processed=5, failed=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a name for the dataset\n",
    "DATASET_NAME = \"test_with_active_learning_test\"\n",
    "\n",
    "# Define labeling schema\n",
    "settings = rb.TextClassificationSettings(label_schema=LABELS)\n",
    "\n",
    "# Create dataset with a label schema\n",
    "rb.configure_dataset(name=DATASET_NAME, settings=settings)\n",
    "\n",
    "# Create records from the initial batch\n",
    "records = [\n",
    "    rb.TextClassificationRecord(\n",
    "        text=ag_news_data[\"train\"][\"text\"][idx],\n",
    "        metadata={\"batch_id\": 0},\n",
    "        id=idx,\n",
    "    )\n",
    "    for idx in initial_indices\n",
    "]\n",
    "\n",
    "# Log initial records to Rubrix\n",
    "rb.log(records, DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassificationRecord(text='Baseball and its fans recover from 1994 strike Ten years after the World Series was canceled and fans left in droves, Major League Baseball will tell you it has never been healthier.', inputs={'text': 'Baseball and its fans recover from 1994 strike Ten years after the World Series was canceled and fans left in droves, Major League Baseball will tell you it has never been healthier.'}, prediction=None, prediction_agent=None, annotation=None, annotation_agent=None, multi_label=False, explanation=None, id=30992, metadata={'batch_id': 0}, status='Default', event_timestamp=None, metrics=None, search_keywords=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rubrix.listeners import listener\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define some helper variables\n",
    "# LABEL2INT = ag_news_data[\"train\"].features[\"label\"].str2int\n",
    "LABEL2INT = dict(zip(LABELS, range(4)))\n",
    "ACCURACIES = []\n",
    "\n",
    "# Set up the active learning loop with the listener decorator\n",
    "@listener(\n",
    "    dataset=DATASET_NAME,\n",
    "    query=\"status:Validated AND metadata.batch_id:{batch_id}\",\n",
    "    condition=lambda search: search.total==NUM_SAMPLES,\n",
    "    execution_interval_in_seconds=3,\n",
    "    batch_id=0\n",
    ")\n",
    "def active_learning_loop(records, ctx):\n",
    "\n",
    "    # 1. Update active learner\n",
    "    print(f\"Updating with batch_id {ctx.query_params['batch_id']} ...\")\n",
    "    print('Please go to rubrix to label the data...')\n",
    "    y = np.array([LABEL2INT[rec.annotation] for rec in records])\n",
    "    \n",
    "    print(f\"{NUM_SAMPLES} records have been labeled updating active learner...\")\n",
    "    # initial update\n",
    "    if ctx.query_params[\"batch_id\"] == 0:\n",
    "        indices = np.array([rec.id for rec in records])\n",
    "        active_learner.initialize_data(indices, y)\n",
    "    # update with the prior queried indices\n",
    "    else:\n",
    "        active_learner.update(y)\n",
    "    print(\"Done!\")\n",
    "    \n",
    "\n",
    "    # 2. Query active learner\n",
    "    print(\"Querying new data points ...\")\n",
    "    queried_indices = active_learner.query(num_samples=NUM_SAMPLES)\n",
    "    ctx.query_params[\"batch_id\"] += 1\n",
    "    new_records = [\n",
    "        rb.TextClassificationRecord(\n",
    "            text=ag_news_data[\"train\"][\"text\"][idx],\n",
    "            metadata={\"batch_id\": ctx.query_params[\"batch_id\"]},\n",
    "            id=idx,\n",
    "        )\n",
    "        for idx in queried_indices\n",
    "    ]\n",
    "\n",
    "    # 3. Log the batch to Rubrix\n",
    "    rb.log(new_records, DATASET_NAME)\n",
    "\n",
    "    # 4. Evaluate current classifier on the test set\n",
    "    print(\"Evaluating current classifier ...\")\n",
    "    accuracy = accuracy_score(\n",
    "        dataset_test.y,\n",
    "        active_learner.classifier.predict(dataset_test),\n",
    "    )\n",
    "    ACCURACIES.append(accuracy)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    print(\"Waiting for annotations ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_learning_loop.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_learning_loop.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.Series(ACCURACIES).plot(xlabel=\"Iteration\", ylabel=\"Accuracy\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.24695833333333334, 0.24845833333333334]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACCURACIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<small_text.integrations.transformers.classifiers.classification.TransformerBasedClassification at 0x7f7a9c5a0880>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_learner.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Musharraf ally elected as new Pakistan PM ISLAMABAD - Pakistan #39;s Parliament elected former Finance Minister Shaukat Aziz as Prime Minister yesterday amid an opposition boycott of the vote.',\n",
       " 'inputs': {'text': 'Musharraf ally elected as new Pakistan PM ISLAMABAD - Pakistan #39;s Parliament elected former Finance Minister Shaukat Aziz as Prime Minister yesterday amid an opposition boycott of the vote.'},\n",
       " 'prediction': None,\n",
       " 'prediction_agent': None,\n",
       " 'annotation': 'World',\n",
       " 'annotation_agent': 'rubrix',\n",
       " 'multi_label': False,\n",
       " 'explanation': None,\n",
       " 'id': '1813',\n",
       " 'metadata': {'batch_id': 1},\n",
       " 'status': 'Validated',\n",
       " 'event_timestamp': None,\n",
       " 'metrics': {'text_length': 192}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb.load(DATASET_NAME).to_datasets()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('weak-supervision-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "290604c3f3ec32082a0d584f0f2181876f072aebaeef66878da63d5158fe7e88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
